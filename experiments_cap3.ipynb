{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6f1d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nicola/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from numpy import float32\n",
    "import json\n",
    "import pandas as pd\n",
    "from preprocessing_text import l_of_ls, invoc\n",
    "from computing_PMI import list_pmi, comp_freq\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "from responsibly.we import weat\n",
    "from matplotlib import pylab as plt\n",
    "from scipy import stats\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pylab as plt\n",
    "import logging\n",
    "import responsibly\n",
    "from responsibly.we import BiasWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a1a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A seed value is fixed for the replicability of experiments\n",
    "seed_value = 42  \n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586f29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading seeds file\n",
    "f = open(os.getcwd()+'/data/seeds/dict_PMI_WE.json')\n",
    "seeds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41cc9123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There could be some seeds that are duplicates. These are removed.\n",
    "for k,v in seeds.items():\n",
    "    seeds[k] = list(set(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae7aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading of sentences tokens\n",
    "with open(os.getcwd()+'/data/tokens/sentences_tokens.txt', 'r') as f:\n",
    "    l1 = []\n",
    "    for ele in f:\n",
    "        line = ele.split()\n",
    "        l1.append(line)\n",
    "tokens_l = list(map(l_of_ls, l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36570b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also if the original file does not contain empy list or None,\n",
    "# the loading process can add these 2 type of elements. So, these\n",
    "# elements are removed.\n",
    "tokens_l = [lst for lst in tokens_l if lst is not None and any(lst)]\n",
    "\n",
    "# Some tokens could contain empty spaces. there are removed.\n",
    "tokens_l = [[t for t in ts if t != ''] for ts in tokens_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6854f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_l is transformed in a single list with all the tokens of all the senteces\n",
    "# for counting the requency of each token.\n",
    "all_tokens = [elemento for lista in tokens_l if lista for elemento in lista]\n",
    "\n",
    "# freq is a dict where the keys are the tokens, and the value the absolute frequency. \n",
    "freq = Counter(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91886d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A group for calculating PMI, for detecting gender bias\n",
    "A_g = seeds[\"espacio_m\"]\n",
    "# B group for calculating PMI, for detecting gender bias\n",
    "B_g = seeds[\"espacio_f\"]\n",
    "# A group for calculating PMI, for detecting religious bias\n",
    "A_r = seeds['christianity words']\n",
    "# B group for calculating PMI, for detecting religious bias\n",
    "B_r = seeds[\"islam words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071ad602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agon√≠a', 'desagradable', 'fracaso', 'terrible', 'horrible', 'guerra']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following keys and associated seeds are removed for creating \n",
    "# a seeds dictionary where each seeds list is represented as X (PMI)\n",
    "seeds.pop(\"espacio_m\") # A_g\n",
    "seeds.pop(\"espacio_f\") #B_g\n",
    "seeds.pop(\"christianity words\") # A_r\n",
    "seeds.pop(\"islam words\") # B_r\n",
    "seeds.pop(\"profesiones_male\") # not usefull for measuring the two types of bias\n",
    "seeds.pop(\"profesiones_female\") # not usefull for measuring the two types of bias\n",
    "seeds.pop(\"islam\") # not usefull for measuring the two types of bias\n",
    "seeds.pop(\"pleasant 6\") # equal to pleasantness\n",
    "seeds.pop(\"unpleasant 6\") # equal to unpleasantness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "# Experiments about Pointwise Mutual Information (PMI)\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing PMI for gender bias case\n",
    "pmi_g = list_pmi(seeds, A_g, B_g, tokens_l, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add, at the values of pmi_g dictionary, the mean frequency of the seeds\n",
    "comp_freq(pmi_g, seeds, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8176a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing PMI for religion bias case\n",
    "pmi_r = list_pmi(seeds, A_r, B_r, tokens_l, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add, at the values of pmi_r dictionary, the mean frequency of the seeds\n",
    "comp_freq(pmi_r, seeds, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89032af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pmi_g to DataFrame\n",
    "df_g = pd.DataFrame.from_dict(pmi_g, orient='index', columns = [\"PMI\", \"freq_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pmi_r to DataFrame\n",
    "df_r = pd.DataFrame.from_dict(pmi_r, orient='index', columns = [\"PMI\", \"freq_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It could be happen that, given a key, that any seeds is contained in the tokens file.\n",
    "# In this case, the key is removed. \n",
    "df_g = df_g[df_g['PMI'] != False]\n",
    "df_r = df_r[df_r['PMI'] != False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1002e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"freq_mean\", y=\"PMI\", data=df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60acb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_g = np.corrcoef(df_g.loc[:,\"PMI\"].astype(float32), df_g.loc[:,\"freq_mean\"].astype(float32))\n",
    "# Correlation coefficient\n",
    "round(r_g[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_r = np.corrcoef(df_r.loc[:,\"PMI\"].astype(float32), df_r.loc[:,\"freq_mean\"].astype(float32))\n",
    "# Correlation coefficient\n",
    "round(r_r[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d15645",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_g.loc[:,\"PMI\"].astype(float32), bins=10, edgecolor='black')\n",
    "plt.xlabel('PMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of $PMI_{gender}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ac303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_r.loc[:,\"PMI\"].astype(float32), bins=10, edgecolor='black')\n",
    "plt.xlabel('PMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of $PMI_{religion}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximated Z score test for gender bias\n",
    "ztest_Score_g, p_value_g = ztest(df_g.loc[:,\"PMI\"], value = 0.0, alternative='two-sided')#0.0053188242738449465 0.00532\n",
    "round(p_value_g,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2310047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximated Z score test for gender bias\n",
    "ztest_Score_r, p_value_r = ztest(df_r.loc[:,\"PMI\"], value = 0.0, alternative='two-sided')#0.12617294102300938 0.12617\n",
    "round(p_value_r,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "# Experiments about Word Embedding \n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be5cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory that contains the 30-d vectors\n",
    "file_path = os.getcwd()+'/data/WE/emb_pr_es_30.vec'\n",
    "model = KeyedVectors.load_word2vec_format(file_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32411d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the most common words in the corpus between 200 and 600\n",
    "words = [word for word in model.index2word[200:600]]\n",
    "\n",
    "# convert the words to vectors\n",
    "embeddings = np.array([model[word] for word in words])\n",
    "\n",
    "# perform T-SNE\n",
    "words_embedded = TSNE(n_components=2).fit_transform(embeddings)\n",
    "\n",
    "# visualize\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, label in enumerate(words):\n",
    "    x, y = words_embedded[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                 ha='right', va='bottom', size=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b70ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object that hands gender bias using the vectors omega\n",
    "we_genero = BiasWordEmbedding(model, only_lower=True)\n",
    "\n",
    "# Computing of the gender bias direction\n",
    "we_genero._identify_direction('Masculino', 'Femenino',\n",
    "                                          definitional=(A_g, B_g),\n",
    "                                          method='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d371adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections plot for exploration purpose\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "we_genero.plot_projection_scores(\n",
    "    seeds[\"math 1\"]+[\"hombre\"]+[\"mujer\"],# + espacio_f[:1] + espacio_m[:1],\n",
    "    n_extreme=20,\n",
    "    ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e65c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "we_relig = BiasWordEmbedding(model, only_lower=True)\n",
    "we_relig._identify_direction('Mundo Cristiano', 'Mundo Isl√°mico',\n",
    "                                          definitional=(A_r, B_r),\n",
    "                                          method='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "we_relig.plot_projection_scores(\n",
    "    random.sample(seeds[\"terrorism\"],10)+[\"misil\"]+['jes√∫s']+['muhammad'],\n",
    "    n_extreme=20,\n",
    "    ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa06a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving of the keys for which was computed PMI in gender case\n",
    "keys_f_g = list(df_g.index)\n",
    "# Retrieving of the keys for which was computed PMI in religion case\n",
    "keys_f_r = list(df_r.index)\n",
    "\n",
    "# Dictionary that will contain the Bolukbasi values for each key (Direct bias values)\n",
    "# gender\n",
    "db_g = {}\n",
    "for k in keys_f_g :\n",
    "    W = list(seeds[k]) \n",
    "    for w in W:    \n",
    "        if w not in we_genero.model.index2word :\n",
    "            W.remove(w)\n",
    "    db_g[k] = we_genero.calc_direct_bias(W, c=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# religion\n",
    "db_r = {}\n",
    "for k in keys_f_r :\n",
    "    W = list(seeds[k]) \n",
    "    for w in W:    \n",
    "        if w not in we_genero.model.index2word :\n",
    "            W.remove(w)\n",
    "    db_r[k] = we_relig.calc_direct_bias(W, c=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4cb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean frequency VS Bolukbasi value for each group of seeds, gender case\n",
    "plt.scatter(df_g.loc[:,\"freq_mean\"], list(db_g.values()), c='blue',s=20, alpha=0.5)\n",
    "plt.xlabel(\"freq_mean\")\n",
    "plt.ylabel(\"bolukbasi metric values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the corr. coef. between the PMI values and Bolukbasi values, gender case\n",
    "\n",
    "r_g2 = np.corrcoef(np.array(df_g.loc[:,\"PMI\"]).astype('float32'), list(db_g.values()))\n",
    "round(r_g2[0,1],2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_g1 = np.corrcoef(df_g.loc[:,\"freq_mean\"], list(db_g.values()))\n",
    "# corr. coef. for (freq_mean,Bolukbasi values), gender case\n",
    "round(r_g1[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5dbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the corr. coef. between the PMI values and Bolukbasi values, religion case\n",
    "\n",
    "r_g2 = np.corrcoef(np.array(df_r.loc[:,\"PMI\"]).astype('float32'), list(db_r.values()))\n",
    "round(r_g2[0,1],2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031d076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean frequency VS Bolukbasi value for each group of seeds, religion case\n",
    "plt.scatter(df_r.loc[:,\"freq_mean\"], list(db_r.values()), c='blue',s=20, alpha=0.5)\n",
    "plt.xlabel(\"freq_mean\")\n",
    "plt.ylabel(\"bolukbasi metric values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_g2 = np.corrcoef(df_r.loc[:,\"freq_mean\"], list(db_r.values()))\n",
    "round(r_g2[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc068675",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the corr. coef. between the PMI values and Bolukbasi values, religion case\n",
    "\n",
    "r_g2 = np.corrcoef(np.array(df_r.loc[:,\"PMI\"]).astype('float32'), list(db_r.values()))\n",
    "round(r_g2[0,1],2)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender bias\n",
    "plt.hist(list(db_g.values()), bins=10, edgecolor='black')\n",
    "plt.xlabel('DirectBias')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Histogram of the Bolukbasi's metric on gender bias\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Religious bias\n",
    "plt.hist(list(db_r.values()), bins=10, edgecolor='black')\n",
    "plt.xlabel('DirectBias')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Histogram of the Bolukbasi's metric on religion bias\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910601b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximated Z score for gender bias\n",
    "ztest_Score_g, p_value_g = ztest(list(db_g.values()), value = 0.0, alternative='two-sided')#3.197867413085225e-78\n",
    "p_value_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b67afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximated Z score for religious bias\n",
    "ztest_Score_r, p_value_r = ztest(list(db_r.values()), value = 0.0, alternative='two-sided')#3.5039766047728225e-36\n",
    "p_value_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################\n",
    "# Experiments about WEAT\n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04fd7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_science_1 =  seeds['math 1'] #X1\n",
    "sa_arts_1 =  seeds['arts 1'] #Y1\n",
    "fa_science_2 =  seeds['science 1'] #X2\n",
    "sa_arts_2 =  seeds['arts 2'] #Y2\n",
    "fa_ins = seeds['instruments'] #X3\n",
    "sa_wea = seeds['weapons'] #Y3\n",
    "fa_car_1 =  seeds['career'] #X4\n",
    "sa_fam_1 =  seeds['family'] #Y4\n",
    "fa_car_2 =  seeds['career words'] #X5\n",
    "sa_fam_2 =  seeds['family words'] #Y5\n",
    "fa_pl_2 =  seeds['pleasantness'] #X6\n",
    "sa_unpl_2 = seeds['unpleasantness'] #Y6\n",
    "\n",
    "# Dictionary with key as the two concepts of Xi,Yi, and the words in Xi, Yi as values for each key\n",
    "# Target sets: (X1, Y1), (X2, Y2), (X3, Y3), ...\n",
    "# Targets sets for gender\n",
    "targ_g = {\"math 1_arts 1\":[fa_science_1, sa_arts_1],\n",
    "          \"science 1_arts 2\":[fa_science_2, sa_arts_2],\n",
    "          \"career_family\":[fa_car_1, sa_fam_1],\n",
    "          \"career words_family words\":[fa_car_2, sa_fam_2],\n",
    "          \"pleasantness_unpleasantness\":[fa_pl_2, sa_unpl_2]\n",
    "         }\n",
    "\n",
    "# Targets sets for religion\n",
    "targ_r = {\n",
    "          \"instruments_weapons\":[fa_ins, sa_wea],\n",
    "          \"pleasantness_unpleasantness\":[fa_pl_2, sa_unpl_2]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7026e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing of the words that have not a vector representation\n",
    "targ_g = invoc(targ_g, we_genero)\n",
    "targ_r = invoc(targ_r, we_relig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cfbcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEAT Gender\n",
    "# The results, w.r.t the thesis, could be different in terms of value BUT NOT in terms of test decisions.\n",
    "# the difference is due to the permutation test done in WEAT by responsibly package \n",
    "first_target, second_target, first_attribute, second_attribute = {}, {}, {}, {}\n",
    "# Attribute set A\n",
    "first_attribute[\"words\"] = A_g\n",
    "first_attribute[\"name\"] = \"masc\"\n",
    "# Attribute set B\n",
    "second_attribute[\"words\"] =  B_g\n",
    "second_attribute[\"name\"] = \"fem\"\n",
    "# List that contains WEAT output\n",
    "l_g = []\n",
    "for k,v in targ_g.items():\n",
    "    if len(v[0]) > len(v[1]) :\n",
    "        length = len(v[1])\n",
    "    else :\n",
    "        length = len(v[0])  \n",
    "    first_target[\"name\"] = k.split(\"_\")[0]\n",
    "    first_target[\"words\"] = random.sample(v[0],length)\n",
    "\n",
    "    second_target[\"name\"] = k.split(\"_\")[1]\n",
    "    second_target[\"words\"] = random.sample(v[1],length)\n",
    "\n",
    "    l_g.append(weat.calc_single_weat(model, first_target, \n",
    "                      second_target, first_attribute, \n",
    "                      second_attribute, with_pvalue=True, pvalue_kwargs=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437b944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEAT Religion\n",
    "# The results, w.r.t the thesis, could be different in terms of value BUT NOT in terms of test decisions.\n",
    "# the difference is due to the permutation test done in WEAT by responsibly package \n",
    "first_target, second_target, first_attribute, second_attribute = {}, {}, {}, {}\n",
    "# Attribute set A\n",
    "first_attribute[\"words\"] = A_r\n",
    "first_attribute[\"name\"] = \"cris\"\n",
    "# Attribute set B\n",
    "second_attribute[\"words\"] = random.sample(B_r, len(A_r))\n",
    "second_attribute[\"name\"] = \"isl\"\n",
    "l_r = []\n",
    "for k,v in targ_r.items() :\n",
    "    if len(v[0]) > len(v[1]) :\n",
    "        length = len(v[1])\n",
    "    else :\n",
    "        length = len(v[0])  \n",
    "    if length > 10:\n",
    "        length = 10\n",
    "    first_target[\"name\"] = k.split(\"_\")[0]\n",
    "    first_target[\"words\"] = random.sample(v[0],length)\n",
    "    second_target[\"name\"] = k.split(\"_\")[1]\n",
    "    second_target[\"words\"] = random.sample(v[1],length)\n",
    "    l_r.append(weat.calc_single_weat(model, first_target, \n",
    "                      second_target, first_attribute, \n",
    "                      second_attribute, with_pvalue=True, pvalue_kwargs=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ce91d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Target words': 'math 1 vs. arts 1',\n",
       "  'Attrib. words': 'masc vs. fem',\n",
       "  's': 0.6327524855732918,\n",
       "  'd': 1.5296344,\n",
       "  'p': 0.001456876456876457,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '9x2'},\n",
       " {'Target words': 'science 1 vs. arts 2',\n",
       "  'Attrib. words': 'masc vs. fem',\n",
       "  's': 0.43256331980228424,\n",
       "  'd': 0.9069404,\n",
       "  'p': 0.05128205128205128,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '9x2'},\n",
       " {'Target words': 'career vs. family',\n",
       "  'Attrib. words': 'masc vs. fem',\n",
       "  's': 0.40579575300216675,\n",
       "  'd': 1.1145061,\n",
       "  'p': 0.032467532467532464,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '9x2'},\n",
       " {'Target words': 'career words vs. family words',\n",
       "  'Attrib. words': 'masc vs. fem',\n",
       "  's': 0.38511137664318085,\n",
       "  'd': 1.2442881,\n",
       "  'p': 0.004079254079254079,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '9x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': 'masc vs. fem',\n",
       "  's': -0.1668972671031952,\n",
       "  'd': -0.5045142,\n",
       "  'p': 0.7824675324675324,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '9x2'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of WEAT for gender bias. The results about targets 'math 1 vs. arts 1' \n",
    "# and 'career words vs. family words' are reported in the thesis\n",
    "l_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d70a22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Target words': 'instruments vs. weapons',\n",
       "  'Attrib. words': 'cris vs. isl',\n",
       "  's': 1.6455432921648026,\n",
       "  'd': 1.4525306,\n",
       "  'p': 8.118816168351773e-05,\n",
       "  'Nt': '10x2',\n",
       "  'Na': '15x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': 'cris vs. isl',\n",
       "  's': 0.2793673425912857,\n",
       "  'd': 0.8637376,\n",
       "  'p': 0.07792207792207792,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '15x2'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of WEAT for religious bias. \n",
    "l_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea492655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# WEAT Gender, with different attributes sets for studying the seeds frequency effects effect \n",
    "first_target, second_target, first_attribute, second_attribute = {}, {}, {}, {}\n",
    "\n",
    "A_g1, B_g1 = ['se√±or','√©l'], ['se√±ora', 'ella']\n",
    "A_g2, B_g2 = ['hombre','padre'], ['mujer', 'madre']\n",
    "A_g3, B_g3 = ['chico','abuelo'], ['chica', 'abuela']\n",
    "l_att = [[A_g1, B_g1], [A_g2, B_g2], [A_g3, B_g3]]\n",
    "\n",
    "l_g1 = []\n",
    "for att in tqdm(l_att):\n",
    "    first_attribute[\"name\"] = str(att[0])\n",
    "    second_attribute[\"name\"] = str(att[1])\n",
    "    first_attribute[\"words\"] = att[0]\n",
    "    second_attribute[\"words\"] = att[1]\n",
    "    for k,v in targ_g.items() :\n",
    "        if len(v[0]) > len(v[1]) :\n",
    "            length = len(v[1])\n",
    "        else :\n",
    "            length = len(v[0])  \n",
    "        first_target[\"name\"] = k.split(\"_\")[0]\n",
    "        first_target[\"words\"] = random.sample(v[0],length)\n",
    "        second_target[\"name\"] = k.split(\"_\")[1]\n",
    "        second_target[\"words\"] = random.sample(v[1],length)\n",
    "        l_g1.append(weat.calc_single_weat(model, first_target, \n",
    "                      second_target, first_attribute, \n",
    "                      second_attribute, with_pvalue=True, pvalue_kwargs=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09740105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:09<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# WEAT Gender, with different attributes sets for studying the seeds frequency effects effect \n",
    "first_target, second_target, first_attribute, second_attribute = {}, {}, {}, {}\n",
    "A_r1, B_r1 = ['iglesia','cristiano'], ['islam', 'musulm√°n']\n",
    "A_r2, B_r2 = ['salvaci√≥n','evangelio'], ['velo', 'mezquita']\n",
    "A_r3, B_r3 = ['mes√≠as','bautismo'], ['sultan', 'allah']\n",
    "l_att = [[A_r1, B_r1], [A_r2, B_r2], [A_r3, B_r3]]\n",
    "\n",
    "l_r1 = []\n",
    "for att in tqdm(l_att):\n",
    "    first_attribute[\"name\"] = str(att[0])\n",
    "    second_attribute[\"name\"] = str(att[1])\n",
    "    first_attribute[\"words\"] = att[0]\n",
    "    second_attribute[\"words\"] = att[1]\n",
    "    for k,v in targ_r.items() :\n",
    "        if len(v[0]) > len(v[1]) :\n",
    "            length = len(v[1])\n",
    "        else :\n",
    "            length = len(v[0]) \n",
    "        if length > 10:\n",
    "            length = 10\n",
    "        first_target[\"name\"] = k.split(\"_\")[0]\n",
    "        first_target[\"words\"] = random.sample(v[0],length)\n",
    "        second_target[\"name\"] = k.split(\"_\")[1]\n",
    "        second_target[\"words\"] = random.sample(v[1],length)\n",
    "        l_r1.append(weat.calc_single_weat(model, first_target, \n",
    "                      second_target, first_attribute, \n",
    "                      second_attribute, with_pvalue=True, pvalue_kwargs=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0fb823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Target words': 'math 1 vs. arts 1',\n",
       "  'Attrib. words': \"['se√±or', '√©l'] vs. ['se√±ora', 'ella']\",\n",
       "  's': 0.7323949933052063,\n",
       "  'd': 1.5870523,\n",
       "  'p': 0.001456876456876457,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'science 1 vs. arts 2',\n",
       "  'Attrib. words': \"['se√±or', '√©l'] vs. ['se√±ora', 'ella']\",\n",
       "  's': 0.5280629396438599,\n",
       "  'd': 1.1130006,\n",
       "  'p': 0.016025641025641024,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career vs. family',\n",
       "  'Attrib. words': \"['se√±or', '√©l'] vs. ['se√±ora', 'ella']\",\n",
       "  's': 0.4626176059246063,\n",
       "  'd': 1.2256644,\n",
       "  'p': 0.01948051948051948,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career words vs. family words',\n",
       "  'Attrib. words': \"['se√±or', '√©l'] vs. ['se√±ora', 'ella']\",\n",
       "  's': 0.5014137327671051,\n",
       "  'd': 1.302963,\n",
       "  'p': 0.005536130536130536,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['se√±or', '√©l'] vs. ['se√±ora', 'ella']\",\n",
       "  's': -0.13719740509986877,\n",
       "  'd': -0.39243847,\n",
       "  'p': 0.7359307359307359,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'math 1 vs. arts 1',\n",
       "  'Attrib. words': \"['hombre', 'padre'] vs. ['mujer', 'madre']\",\n",
       "  's': 0.6634618639945984,\n",
       "  'd': 1.3706245,\n",
       "  'p': 0.005244755244755245,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'science 1 vs. arts 2',\n",
       "  'Attrib. words': \"['hombre', 'padre'] vs. ['mujer', 'madre']\",\n",
       "  's': 0.3454829007387161,\n",
       "  'd': 0.53724056,\n",
       "  'p': 0.175990675990676,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career vs. family',\n",
       "  'Attrib. words': \"['hombre', 'padre'] vs. ['mujer', 'madre']\",\n",
       "  's': 0.17213934659957886,\n",
       "  'd': 0.3484365,\n",
       "  'p': 0.3008658008658009,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career words vs. family words',\n",
       "  'Attrib. words': \"['hombre', 'padre'] vs. ['mujer', 'madre']\",\n",
       "  's': 0.14097860455513,\n",
       "  'd': 0.5012121,\n",
       "  'p': 0.1993006993006993,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['hombre', 'padre'] vs. ['mujer', 'madre']\",\n",
       "  's': -0.25965219736099243,\n",
       "  'd': -0.71921074,\n",
       "  'p': 0.8766233766233766,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'math 1 vs. arts 1',\n",
       "  'Attrib. words': \"['chico', 'abuelo'] vs. ['chica', 'abuela']\",\n",
       "  's': 0.5240679606795311,\n",
       "  'd': 1.1382422,\n",
       "  'p': 0.01893939393939394,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'science 1 vs. arts 2',\n",
       "  'Attrib. words': \"['chico', 'abuelo'] vs. ['chica', 'abuela']\",\n",
       "  's': 0.49621744453907013,\n",
       "  'd': 0.9298969,\n",
       "  'p': 0.047494172494172496,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career vs. family',\n",
       "  'Attrib. words': \"['chico', 'abuelo'] vs. ['chica', 'abuela']\",\n",
       "  's': 0.4425674378871918,\n",
       "  'd': 1.0480517,\n",
       "  'p': 0.04220779220779221,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'career words vs. family words',\n",
       "  'Attrib. words': \"['chico', 'abuelo'] vs. ['chica', 'abuela']\",\n",
       "  's': 0.4476238191127777,\n",
       "  'd': 1.0910933,\n",
       "  'p': 0.019522144522144524,\n",
       "  'Nt': '7x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['chico', 'abuelo'] vs. ['chica', 'abuela']\",\n",
       "  's': -0.23933210968971252,\n",
       "  'd': -0.58905655,\n",
       "  'p': 0.8246753246753247,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of WEAT gender for different attributes sets\n",
    "l_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dec360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Target words': 'instruments vs. weapons',\n",
       "  'Attrib. words': \"['iglesia', 'cristiano'] vs. ['islam', 'musulm√°n']\",\n",
       "  's': 1.6629449054598808,\n",
       "  'd': 1.2523228,\n",
       "  'p': 0.0021596051007815712,\n",
       "  'Nt': '10x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['iglesia', 'cristiano'] vs. ['islam', 'musulm√°n']\",\n",
       "  's': 0.6260063201189041,\n",
       "  'd': 1.2141101,\n",
       "  'p': 0.017316017316017316,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'instruments vs. weapons',\n",
       "  'Attrib. words': \"['salvaci√≥n', 'evangelio'] vs. ['velo', 'mezquita']\",\n",
       "  's': 1.4136398285627365,\n",
       "  'd': 1.5881547,\n",
       "  'p': 3.78878087856416e-05,\n",
       "  'Nt': '10x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['salvaci√≥n', 'evangelio'] vs. ['velo', 'mezquita']\",\n",
       "  's': 0.6587641835212708,\n",
       "  'd': 1.3027245,\n",
       "  'p': 0.01406926406926407,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'instruments vs. weapons',\n",
       "  'Attrib. words': \"['mes√≠as', 'bautismo'] vs. ['sultan', 'allah']\",\n",
       "  's': 2.0459301322698593,\n",
       "  'd': 1.632102,\n",
       "  'p': 2.7062720561172574e-05,\n",
       "  'Nt': '10x2',\n",
       "  'Na': '2x2'},\n",
       " {'Target words': 'pleasantness vs. unpleasantness',\n",
       "  'Attrib. words': \"['mes√≠as', 'bautismo'] vs. ['sultan', 'allah']\",\n",
       "  's': 0.03908431529998779,\n",
       "  'd': 0.08524161,\n",
       "  'p': 0.44155844155844154,\n",
       "  'Nt': '6x2',\n",
       "  'Na': '2x2'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of WEAT religious for different attributes sets\n",
    "l_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da7c8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19970.75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean frequencies\n",
    "(freq['se√±or']+freq['√©l']+freq['se√±ora']+freq['ella'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c32883ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.75"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(freq['chico']+freq['abuelo']+freq['chica']+freq['abuela'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e23f443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(freq['iglesia']+freq['cristiano']+freq['islam']+freq['musulm√°n'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aec9544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(freq['mes√≠as']+freq['bautismo']+freq['sultan']+freq['allah'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b71d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
